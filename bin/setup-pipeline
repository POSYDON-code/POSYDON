#!/usr/bin/env python
import os
import pandas as pd
import numpy as np
from posydon.utils.common_functions import PATH_TO_POSYDON

# this data processing pipeline was designed assuming POSYDON v2 data structure
VERSION = 'v2'
'''
Data tree structure

PATH_TO_GRIDS/
    /HMS-HMS/
    /CO-HMS_RLO/
    /CO-HeMS/
    /single_HMS/
    /single_HeMS/
        /v1/
        /v2/
            /1e+00_Zsun/
            /1e-01_Zsun/
            /1e-02_Zsun/
            ...
                /grid_low_res_0/
                /grid_low_res_1/
                /grid_rerun_1/
                ...
                /LITE/
                /ORIGINAL/
                /logs/
                /scripts/
                /plots/
                    /grid_low_res_combined/
                        /TF1/
                        /TF2/
                        ...
'''

def slurm_job(CREATE_GRID_SLICES=False,
              COMBINE_GRID_SLICES=False,
              PLOT_GRIDS=False,
              TRAIN_INTERPOLATORS=False,
              verbose=False,
              ):
    with open('post_processing.slurm', 'w') as f:
        f.write("#!/bin/bash\n")
        f.write("#SBATCH --account=b1119\n")
        f.write("#SBATCH --partition=posydon-priority\n")
        f.write("#SBATCH -N 1\n")
        f.write("#SBATCH --cpus-per-task 1\n")
        f.write("#SBATCH --ntasks-per-node 1\n")
        f.write("#SBATCH --time=24:00:00\n")
        f.write("#SBATCH --job-name=psygrid\n")
        f.write("#SBATCH --mem-per-cpu=4G\n")

        if EMAIL is not None:
            f.write("#SBATCH --mail-type=ALL\n")
            f.write(f"#SBATCH --mail-user={EMAIL}\n")

        if CREATE_GRID_SLICES:
            df = pd.read_csv(os.path.join(PATH,"step_1.csv"))
            N = df.shape[0]-1
            f.write(f"#SBATCH --array=0-{N}\n")
            f.write(f"#SBATCH --output={PATH}/logs/grid_slice_%a.out\n")
            f.write(f"\nsrun python {PATH_TO_POSYDON}/bin/run-pipeline $SLURM_ARRAY_TASK_ID")

        if COMBINE_GRID_SLICES:
            f.write(f"#SBATCH --output={PATH}/logs/combine_grid_slices.out\n")
            f.write(f"\nsrun python {PATH_TO_POSYDON}/bin/run-pipeline")

        if PLOT_GRIDS:
            df = pd.read_csv(os.path.join(PATH,"step_3.csv"))
            N = df.shape[0]-1
            f.write(f"#SBATCH --array=0-{N}\n")
            f.write(f"#SBATCH --output={PATH}/logs/plot_grid_%a.out\n")
            f.write(f"\nsrun python {PATH_TO_POSYDON}/bin/run-pipeline")

        if TRAIN_INTERPOLATORS:
            f.write(f"export PATH_TO_POSYDON={PATH_TO_POSYDON}\n")
            f.write(f"\nsrun python {PATH_TO_POSYDON}/bin/run-pipeline" + train_interpolators)

# create csv file with a list of all grid paths to process
def create_csv_step_1(GRID_TYPES, METALLICITIES, GRID_SLICES, COMPRESSIONS,
                      version=VERSION):

    grids = []
    for grid_type in GRID_TYPES:
        for metallicity in METALLICITIES:
            for grid_slice in GRID_SLICES:
                for compression in COMPRESSIONS:
                    grids.append([os.path.join(PATH_TO_GRIDS,
                                  grid_type, version, metallicity, grid_slice),
                                  compression])
    grids = np.array(grids)
    df = pd.DataFrame()
    df['path_to_grid'] = grids[:,0]
    df['compression'] = grids[:,1]
    df.to_csv(os.path.join(PATH,'step_1.csv'), index=False)

def create_csv_step_2(GRID_TYPES, METALLICITIES, GRID_SLICES,
                      GRIDS_COMBINED, COMPRESSIONS, version=VERSION):

    if len(GRID_SLICES) != len(GRIDS_COMBINED):
        raise ValueError('len(GRID_SLICES) =! len(GRIDS_COMBINED)!')

    df = pd.DataFrame()
    for grid_type in GRID_TYPES:
        for metallicity in METALLICITIES:
            for i, grid_slice_batch in enumerate(GRID_SLICES):
                for k, compression in enumerate(COMPRESSIONS):
                    combine_grid_slices = []
                    for grid_slice in grid_slice_batch:
                            path_to_grid = os.path.join(PATH_TO_GRIDS,
                                          grid_type, version, metallicity,
                                          compression, grid_slice+'.h5')
                            combine_grid_slices.append(path_to_grid)
                    path_to_grid_combined = os.path.join(PATH_TO_GRIDS,
                                                         grid_type, version,
                                                         metallicity,
                                                         compression,
                                                         GRIDS_COMBINED[i]+'.h5')
                    df_tmp = pd.DataFrame()
                    df_tmp[path_to_grid_combined] = combine_grid_slices
                    df = pd.concat([df,df_tmp], axis=1)
    df.to_csv(os.path.join(PATH,'step_2.csv'), index=False)

def create_csv_step_3(GRID_TYPES, METALLICITIES, GRID_SLICES, COMPRESSIONS,
                      version=VERSION):

    grids = []
    plot_dirs = []
    for grid_type in GRID_TYPES:
        for metallicity in METALLICITIES:
            for grid_slice in GRID_SLICES:
                for compression in COMPRESSIONS:
                    grids.append(os.path.join(PATH_TO_GRIDS,
                                  grid_type, version, metallicity,
                                  compression, grid_slice+'.h5'))
                    plot_dirs.append(os.path.join(PATH_TO_GRIDS,
                                grid_type, version, metallicity,
                                'plots', grid_slice))
    grids = np.array(grids)
    df = pd.DataFrame()
    df['path_to_grid'] = grids
    df['path_to_plot'] = plot_dirs
    df.to_csv(os.path.join(PATH,'step_3.csv'), index=False)

if __name__ == '__main__':

    PATH_TO_GRIDS = '/projects/b1119/POSYDON_GRIDS/'
    PATH = '.'
    EMAIL = 'simone.bavera@unige.ch'
    VERBOSE = True

    CREATE_GRID_SLICES = False
    if CREATE_GRID_SLICES:
        ###### EXAMPLE ######
        GRID_TYPES = ['HMS-HMS']
        METALLICITIES = ['1e-01_Zsun']
        GRID_SLICES = ['grid_low_res_0','grid_low_res_1','grid_low_res_2',
                        'grid_low_res_3','grid_low_res_4','grid_low_res_5',
                        'grid_rerun_opacitymax']
        COMPRESSIONS = ['LITE','ORIGINAL']
        #####################
        create_csv_step_1(GRID_TYPES, METALLICITIES, GRID_SLICES, COMPRESSIONS)

        # create the slurm job
        slurm_job(CREATE_GRID_SLICES=CREATE_GRID_SLICES, verbose=VERBOSE)

    COMBINE_GRID_SLICES = False
    if COMBINE_GRID_SLICES:
        ###### EXAMPLE ######
        GRID_TYPES = ['HMS-HMS']
        METALLICITIES = ['1e-01_Zsun']
        GRID_SLICES = [['grid_low_res_0','grid_low_res_1','grid_low_res_2',
                        'grid_low_res_3','grid_low_res_4','grid_low_res_5'],
                        ['grid_low_res_combined','grid_low_res_rerun_opacitymax'],
                        ]
        GRIDS_COMBINED = ['grid_low_res_combined','grid_low_res_combined_rerun_1']
        COMPRESSIONS = ['LITE','ORIGINAL']
        #####################
        create_csv_step_2(GRID_TYPES, METALLICITIES, GRID_SLICES,
                          GRIDS_COMBINED, COMPRESSIONS)

        # create the slurm job
        slurm_job(COMBINE_GRID_SLICES=COMBINE_GRID_SLICES, verbose=VERBOSE)

    PLOT_GRIDS = True
    if PLOT_GRIDS:
        ###### EXAMPLE ######
        GRID_TYPES = ['HMS-HMS']
        METALLICITIES = ['1e-01_Zsun']
        GRID_SLICES = ['grid_low_res_combined','grid_low_res_rerun_opacitymax',
                       'grid_low_res_combined_rerun_1']
        COMPRESSIONS = ['LITE']
        #####################
        create_csv_step_3(GRID_TYPES, METALLICITIES, GRID_SLICES, COMPRESSIONS)

        # create the slurm job
        slurm_job(PLOT_GRIDS=PLOT_GRIDS, verbose=VERBOSE)

    # create logs dire where we store all slurm outputs
    logs_path = os.path.join(PATH,'logs')
    if not os.path.isdir(logs_path):
        os.makedirs(logs_path)

    # TODO: check that LITE/ ORIGINAL/ plots/ are present in all directories
