#!/usr/bin/env python
__authors__ = [
    "Simone Bavera <Simone.Bavera@unige.ch>",
]

import os
import sys
import pandas as pd
import numpy as np
from posydon.utils.common_functions import PATH_TO_POSYDON

# this data processing pipeline was designed assuming POSYDON v2 data structure
VERSION = '' # quest: 'v2' yggdrasil: ''
'''
Data tree structure

PATH_TO_GRIDS/
    /HMS-HMS/
    /CO-HMS_RLO/
    /CO-HeMS/
    /single_HMS/
    /single_HeMS/
        /v1/
        /v2/
            /1e+00_Zsun/
            /1e-01_Zsun/
            /1e-02_Zsun/
            ...
                /grid_low_res_0/
                /grid_low_res_1/
                /grid_rerun_1/
                ...
                /LITE/
                /ORIGINAL/
                /logs/
                /scripts/
                /plots/
                    /grid_low_res_combined/
                        /TF1/
                        /TF2/
                        ...
'''

def slurm_job(job_name,
              CREATE_GRID_SLICES=False,
              COMBINE_GRID_SLICES=False,
              PLOT_GRIDS=False,
              CHECK_FAILURE_RATE=False,
              POST_PROCESSING=False,
              TRAIN_INTERPOLATORS=False,
              EXPORT_DATASET=False,
              RERUN=False,
              rerun_type='',
              verbose=False,
              ):

    path_to_csv_file = os.path.join(PATH,f"{job_name}.csv")

    with open(f'{job_name}.slurm', 'w') as f:
        f.write("#!/bin/bash\n")
        f.write(f"#SBATCH --account={ACCOUNT}\n")
        f.write(f"#SBATCH --partition={PARTITION}\n")
        f.write("#SBATCH -N 1\n")
        f.write("#SBATCH --cpus-per-task 1\n")
        f.write("#SBATCH --ntasks-per-node 1\n")
        f.write(f"#SBATCH --time={WALLTIME}\n")
        f.write("#SBATCH --job-name=psygrid\n")
        f.write("#SBATCH --mem-per-cpu=4G\n")

        if EMAIL is not None:
            f.write(f"#SBATCH --mail-type={MAILTYPE}\n")
            f.write(f"#SBATCH --mail-user={EMAIL}\n")

        slurm_array = ''
        if (CREATE_GRID_SLICES or PLOT_GRIDS or CHECK_FAILURE_RATE or
            POST_PROCESSING or TRAIN_INTERPOLATORS or EXPORT_DATASET or
            RERUN):
            df = pd.read_csv(path_to_csv_file)
            N = df.shape[0]-1
            f.write(f"#SBATCH --array=0-{N}\n")
            slurm_array = '$SLURM_ARRAY_TASK_ID'

        if CREATE_GRID_SLICES:
            f.write(f"#SBATCH --output={PATH}/logs/grid_slice_%a.out\n")

        if COMBINE_GRID_SLICES:
            f.write(f"#SBATCH --output={PATH}/logs/combine_grid_slices.out\n")

        if PLOT_GRIDS:
            f.write(f"#SBATCH --output={PATH}/logs/plot_grid.out\n")

        if CHECK_FAILURE_RATE:
            f.write(f"#SBATCH --output={PATH}/logs/check_failure_rate.out\n")

        if POST_PROCESSING:
            f.write(f"#SBATCH --output={PATH}/logs/post_processing_%a.out\n")
            f.write(f"export PATH_TO_POSYDON={PATH_TO_POSYDON}\n")

        if TRAIN_INTERPOLATORS:
            f.write(f"#SBATCH --output={PATH}/logs/train_interpolators_%a.out\n")

        if EXPORT_DATASET:
            f.write(f"#SBATCH --output={PATH}/logs/export_dataset.out\n")

        if RERUN:
            f.write(f"#SBATCH --output={PATH}/logs/rerun.out\n")

        f.write(f"\nsrun python {PATH_TO_POSYDON}/bin/run-pipeline {path_to_csv_file} {slurm_array} {rerun_type}")

# create csv file with a list of all grid paths to process
def create_csv(GRID_TYPES, METALLICITIES, GRID_SLICES, COMPRESSIONS,
               step_name=None, version=VERSION, GRIDS_COMBINED=None,
               INTERPOLATION_METHODS=None, rerun_type=''):

    # number of grid types
    N = len(GRID_TYPES)
    if ( N != len(METALLICITIES) or N != len(GRID_SLICES) or
         N != len(COMPRESSIONS)):
        raise ValueError('Missmatch between the len of GRID_TYPES, '
                         'METALLICITIES, GRID_SLICES, COMPRESSIONS.')

    grids = []
    grids_compression = []
    plot_dirs = []
    processed_grids = []
    interpolators = []
    export_path = []
    rerun_path = []
    df = pd.DataFrame()
    for l, grid_type in enumerate(GRID_TYPES):

        METALLICITIES_ = METALLICITIES[l]
        GRID_SLICES_ = GRID_SLICES[l]
        COMPRESSIONS_ = COMPRESSIONS[l]

        for metallicity in METALLICITIES_:
            for i, grid_slice in enumerate(GRID_SLICES_):
                for compression in COMPRESSIONS_:
                    if step_name == 'step_1':
                        grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity, grid_slice))
                        grids_compression.extend([compression])
                    elif step_name == 'step_2':
                        if N != len(GRIDS_COMBINED):
                            raise ValueError('len(GRID_TYPES) != len(GRIDS_COMBINED)!')
                        if len(GRID_SLICES[l]) != len(GRIDS_COMBINED[l]):
                            raise ValueError('len(GRID_SLICES[l]) != len(GRIDS_COMBINED[l])!')
                        combine_grid_slices = []
                        # grid_slice is a batch
                        for grid_slice_ in grid_slice:
                                path_to_grid = os.path.join(PATH_TO_GRIDS,
                                              grid_type, version, metallicity,
                                              compression, grid_slice_+'.h5')
                                combine_grid_slices.append(path_to_grid)
                        path_to_grid_combined = os.path.join(PATH_TO_GRIDS,
                                                             grid_type, version,
                                                             metallicity,
                                                             compression,
                                                             GRIDS_COMBINED[l][i]+'.h5')
                        df_tmp = pd.DataFrame()
                        df_tmp[path_to_grid_combined] = combine_grid_slices
                        df = pd.concat([df,df_tmp], axis=1)
                    elif step_name == 'step_3':
                        grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity,
                                      compression, grid_slice+'.h5'))
                        plot_dirs.append(os.path.join(PATH_TO_GRIDS,
                                    grid_type, version, metallicity,
                                    'plots', grid_slice))
                    elif step_name == 'step_4':
                        grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity,
                                      compression, grid_slice+'.h5'))
                    elif step_name == 'step_5':
                        grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity,
                                      compression, grid_slice+'.h5'))
                        processed_grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity,
                                      compression, grid_slice+'_processed.h5'))
                    elif step_name == 'step_6':
                        for method in INTERPOLATION_METHODS:
                            grids.append(os.path.join(PATH_TO_GRIDS,
                                          grid_type, version, metallicity,
                                          compression, grid_slice+'.h5'))
                            interpolators.append(os.path.join(PATH_TO_GRIDS,
                                          grid_type, version, metallicity,
                                          'interpolation_objects',
                                          'IF_'+method+'.pkl'))
                    elif step_name == 'step_7':
                        grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity,
                                      compression, grid_slice+'.h5'))
                        export_path.append(os.path.join(PATH, 'POSYDON_data',
                                                        grid_type,
                                                        metallicity+'.h5'))
                        for method in [['linear','linear3c_kNN'],
                                        ['1NN','1NN_1NN']]:
                            grids.append(os.path.join(PATH_TO_GRIDS,
                                          grid_type, version, metallicity,
                                          'interpolation_objects',
                                          'IF_'+method[0]+'.pkl'))
                            export_path.append(os.path.join(PATH, 'POSYDON_data',
                                                            grid_type,
                                                            'interpolators',
                                                            method[1],
                                                            metallicity+'.pkl'))
                    elif step_name == 'rerun':
                        grids.append(os.path.join(PATH_TO_GRIDS,
                                      grid_type, version, metallicity,
                                      compression, grid_slice+'.h5'))
                        rerun_path.append(os.path.join(PATH_TO_GRIDS, grid_type,
                                     version, metallicity, 'rerun_'+rerun_type))

    # saving dataset to csv file
    if step_name != 'step_2':
        grids = np.array(grids)
        df['path_to_grid'] = grids
        if step_name == 'step_1':
            df['compression'] = grids_compression
        elif step_name == 'step_3':
            df['path_to_plot'] = plot_dirs
        elif step_name == 'step_5':
            df['path_to_processed_grid'] = processed_grids
        elif step_name == 'step_6':
            df['path_to_interpolator'] = interpolators
        elif step_name == 'step_7':
            df['export_path'] = export_path
        elif step_name == 'rerun':
            df['rerun_path'] = rerun_path
    output_fname = f'{step_name}.csv'
    df.to_csv(os.path.join(PATH, output_fname), index=False)

if __name__ == '__main__':

    # TODO: use args parser
    # setup-pipeline takes an input only for the rerun method
    if len(sys.argv) == 2:
        rerun_type = str(sys.argv[1])

    EXAMPLE = 'yggdrasil'

    # run a test on quest, currently only HMS-HMS grids are available
    if EXAMPLE == 'quest':

        PATH_TO_GRIDS = '/projects/b1119/POSYDON_GRIDS/'
        PATH = '.' # working dir
        ACCOUNT = 'b1119'
        PARTITION = 'posydon-priority'
        WALLTIME = '24:00:00'
        MAILTYPE = 'FAIL'
        EMAIL = 'simone.bavera@unige.ch'
        VERBOSE = True

        # EXAMPLE SETUP (they currently run independently)
        # TODO: add a linked slurm job arrays which are waiting for each others
        # STEPS 1 to 6
        CREATE_GRID_SLICES = True
        COMBINE_GRID_SLICES = True
        PLOT_GRIDS = True
        CHECK_FAILURE_RATE = True
        POST_PROCESSING = True
        TRAIN_INTERPOLATORS = True
        EXPORT_DATASET = True
        RERUN = True

        ###### EXAMPLE step 1 ######
        GRID_TYPES_s1 = ['HMS-HMS']
        METALLICITIES_s1 = [['1e-01_Zsun']]
        GRID_SLICES_s1 = [# HMS-HMS
                          ['grid_low_res_0','grid_low_res_1','grid_low_res_2',
                           'grid_low_res_3','grid_low_res_4','grid_low_res_5',
                           'grid_low_res_rerun_opacitymax']
                          ]
        COMPRESSIONS_s1 = [['LITE','ORIGINAL']]

        ###### EXAMPLE step 2 ######
        GRID_TYPES_s2 = ['HMS-HMS']
        METALLICITIES_s2 = [['1e-01_Zsun']]
        GRID_SLICES_s2 = [# HMS-HMS
                          [['grid_low_res_0','grid_low_res_1','grid_low_res_2',
                            'grid_low_res_3','grid_low_res_4','grid_low_res_5'],
                           ['grid_low_res_combined','grid_low_res_rerun_opacitymax']]
                          ]
        GRIDS_COMBINED_s2 = [# HMS-HMS
                             ['grid_low_res_combined','grid_low_res_combined_rerun_1']
                             ]
        COMPRESSIONS_s2 = [['LITE','ORIGINAL']]

        ###### EXAMPLE step 3 ######
        GRID_TYPES_s3 = ['HMS-HMS']
        METALLICITIES_s3 = [['1e-01_Zsun']]
        GRID_SLICES_s3 = [['grid_low_res_combined','grid_low_res_rerun_opacitymax',
                       'grid_low_res_combined_rerun_1']]
        COMPRESSIONS_s3 = [['LITE']]

        ###### EXAMPLE step 4 ######
        GRID_TYPES_s4 = ['HMS-HMS']
        METALLICITIES_s4 = [['1e-01_Zsun']]
        GRID_SLICES_s4 = [['grid_low_res_combined','grid_low_res_rerun_opacitymax',
                       'grid_low_res_combined_rerun_1']]
        COMPRESSIONS_s4 = [['LITE']]

        ###### EXAMPLE step 5 ######
        GRID_TYPES_s5 = ['HMS-HMS']
        METALLICITIES_s5 = [['1e-01_Zsun']]
        GRID_SLICES_s5 = [['grid_low_res_combined_rerun_1']]
        COMPRESSIONS_s5 = [['LITE']]

        ###### EXAMPLE step 6 ######
        GRID_TYPES_s6 = ['HMS-HMS']
        METALLICITIES_s6 = [['1e-01_Zsun']]
        GRID_SLICES_s6 = [['grid_low_res_combined_rerun_1_processed']]
        INTERPOLATION_METHODS_s6 = ["linear","1NN"]
        COMPRESSIONS_s6 = [['LITE']]

        ###### EXAMPLE step 7 ######
        GRID_TYPES_s7 = ['HMS-HMS']
        METALLICITIES_s7 = [['1e-01_Zsun']]
        GRID_SLICES_s7 = [['grid_low_res_combined_rerun_1_processed']]
        COMPRESSIONS_s7 = [['LITE']]

        ###### EXAMPLE rerun ######
        GRID_TYPES_r = ['HMS-HMS']
        METALLICITIES_r = [['1e+00_Zsun']]
        GRID_SLICES_r = [['grid_low_res_combined']]
        COMPRESSIONS_r = [['LITE']]

    elif EXAMPLE == 'yggdrasil':

        PATH_TO_GRIDS = '/srv/beegfs/scratch/shares/astro/posydon/POSYDON_GRIDS_v2/'
        PATH = '.' # working dir
        ACCOUNT = 'meynet'
        PARTITION = 'shared-cpu'
        WALLTIME = '08:00:00'
        MAILTYPE = 'FAIL'
        EMAIL = 'simone.bavera@unige.ch'
        VERBOSE = True

        # EXAMPLE SETUP (they currently run independently)
        # TODO: add a linked slurm job arrays which are waiting for each others
        # STEPS 1 to 7
        CREATE_GRID_SLICES = True
        COMBINE_GRID_SLICES = True
        PLOT_GRIDS = True
        CHECK_FAILURE_RATE = True
        POST_PROCESSING = True
        TRAIN_INTERPOLATORS = True
        EXPORT_DATASET = True
        RERUN = True

        ###### EXAMPLE step 1 ######
        GRID_TYPES_s1 = ['CO-HMS_RLO','CO-HeMS','HMS-HMS']
        METALLICITIES_s1 = [['1e-01_Zsun'],['1e-01_Zsun'],['1e-04_Zsun']]
        GRID_SLICES_s1 = [# CO-HMS
                          ['grid_low_res_0','grid_low_res_1','grid_low_res_2',
                           'grid_random_1'],
                          # CO-HeMS
                          ['grid_low_res_0','grid_low_res_1','grid_low_res_2',
                           'grid_random_1'],
                          # HMS-HMS
                          ['grid_low_res_3','grid_low_res_4','grid_low_res_5',
                           'grid_random_1']
                          ]
        COMPRESSIONS_s1 = [['LITE','ORIGINAL'],['LITE','ORIGINAL'],['LITE','ORIGINAL']]

        ###### EXAMPLE step 2 ######
        GRID_TYPES_s2 = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_s2 = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_s2 = [# CO-HMS
                          [['grid_low_res_0','grid_low_res_1','grid_low_res_2']],
                          # CO-HeMS
                          [['grid_low_res_0','grid_low_res_1','grid_low_res_2']],
                          ]
        GRIDS_COMBINED_s2 = [# CO-HMS
                             ['grid_low_res_combined'],
                             # CO-HeMS
                             ['grid_low_res_combined']
                             ]
        COMPRESSIONS_s2 = [['LITE','ORIGINAL'],['LITE','ORIGINAL']]

        ###### EXAMPLE step 3 ######
        GRID_TYPES_s3 = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_s3 = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_s3 = [['grid_low_res_combined'],['grid_low_res_combined']]
        COMPRESSIONS_s3 = [['LITE'],['LITE']]

        ###### EXAMPLE step 4 ######
        GRID_TYPES_s4 = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_s4 = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_s4 = [['grid_low_res_combined'],['grid_low_res_combined']]
        COMPRESSIONS_s4 = [['LITE'],['LITE']]

        ###### EXAMPLE step 5 ######
        GRID_TYPES_s5 = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_s5 = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_s5 = [['grid_low_res_combined'],
                          ['grid_low_res_combined']]
        COMPRESSIONS_s5 = [['LITE'],['LITE']]

        ###### EXAMPLE step 6 ######
        GRID_TYPES_s6 = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_s6 = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_s6 = [['grid_low_res_combined_processed'],
                          ['grid_low_res_combined_processed']]
        INTERPOLATION_METHODS_s6 = ["linear","1NN"]
        COMPRESSIONS_s6 = [['LITE'],['LITE']]

        ###### EXAMPLE step 7 ######
        GRID_TYPES_s7 = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_s7 = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_s7 = [['grid_low_res_combined_processed'],
                          ['grid_low_res_combined_processed']]
        COMPRESSIONS_s7 = [['LITE'],['LITE']]

        ###### EXAMPLE rerun ######
        GRID_TYPES_r = ['CO-HMS_RLO','CO-HeMS']
        METALLICITIES_r = [['1e-01_Zsun'],['1e-01_Zsun']]
        GRID_SLICES_r = [['grid_low_res_combined'],
                          ['grid_low_res_combined']]
        COMPRESSIONS_r = [['LITE'],['LITE']]

    if CREATE_GRID_SLICES:
        create_csv(GRID_TYPES_s1, METALLICITIES_s1, GRID_SLICES_s1,
                   COMPRESSIONS_s1, step_name='step_1')
        slurm_job(job_name='step_1',
                  CREATE_GRID_SLICES=CREATE_GRID_SLICES,
                  verbose=VERBOSE)

    if COMBINE_GRID_SLICES:
        create_csv(GRID_TYPES_s2, METALLICITIES_s2, GRID_SLICES_s2, COMPRESSIONS_s2,
                   step_name='step_2', GRIDS_COMBINED=GRIDS_COMBINED_s2)
        slurm_job(job_name='step_2',
                  COMBINE_GRID_SLICES=COMBINE_GRID_SLICES,
                  verbose=VERBOSE)

    if PLOT_GRIDS:
        create_csv(GRID_TYPES_s3, METALLICITIES_s3, GRID_SLICES_s3,
                   COMPRESSIONS_s3, step_name='step_3')
        slurm_job(job_name='step_3',
                  PLOT_GRIDS=PLOT_GRIDS,
                  verbose=VERBOSE)

    if CHECK_FAILURE_RATE:
        create_csv(GRID_TYPES_s4, METALLICITIES_s4, GRID_SLICES_s4,
                   COMPRESSIONS_s4, step_name='step_4')
        slurm_job(job_name='step_4',
                  CHECK_FAILURE_RATE=CHECK_FAILURE_RATE,
                  verbose=VERBOSE)

    if POST_PROCESSING:
        create_csv(GRID_TYPES_s5, METALLICITIES_s5, GRID_SLICES_s5,
                   COMPRESSIONS_s5, step_name='step_5')
        slurm_job(job_name='step_5',
                  POST_PROCESSING=POST_PROCESSING,
                  verbose=VERBOSE)

    if TRAIN_INTERPOLATORS:
        create_csv(GRID_TYPES_s6, METALLICITIES_s6, GRID_SLICES_s6,
                   COMPRESSIONS_s6, step_name='step_6',
                   INTERPOLATION_METHODS=INTERPOLATION_METHODS_s6)
        slurm_job(job_name='step_6',
                  TRAIN_INTERPOLATORS=TRAIN_INTERPOLATORS,
                  verbose=VERBOSE)

    if EXPORT_DATASET:
        create_csv(GRID_TYPES_s7, METALLICITIES_s7, GRID_SLICES_s7,
                   COMPRESSIONS_s7, step_name='step_7')
        slurm_job(job_name='step_7',
                  EXPORT_DATASET=EXPORT_DATASET,
                  verbose=VERBOSE)

    if RERUN:
        create_csv(GRID_TYPES_r, METALLICITIES_r, GRID_SLICES_r,
                   COMPRESSIONS_r, step_name='rerun', rerun_type=rerun_type)
        slurm_job(job_name='rerun',
                  RERUN=RERUN,
                  rerun_type=rerun_type,
                  verbose=VERBOSE)

    # create logs in working dir to store all slurm outputs
    logs_path = os.path.join(PATH,'logs')
    if not os.path.isdir(logs_path):
        os.makedirs(logs_path)

    # create data dir three to export the datasets
    if EXPORT_DATASET:
        data_path = os.path.join(PATH, 'POSYDON_data')
        if not os.path.isdir(data_path):
            os.makedirs(data_path)

            dirs = []
            grid_dirs = ['HMS-HMS', 'CO-HMS_RLO', 'CO-HeMS', 'single_HMS',
                        'single_HeMS']
            interp_dirs = ['interpolators', 'interpolators/1NN_1NN',
                           'interpolators/linear3c_kNN']
            for name1 in grid_dirs:
                dirs.append(os.path.join(data_path,name1))
                for name2 in interp_dirs:
                    dirs.append(os.path.join(data_path,name1,name2))

            for dir_ in  dirs:
                if not os.path.isdir(dir_):
                    os.makedirs(dir_)
